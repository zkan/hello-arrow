{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frequent-dispute",
   "metadata": {},
   "source": [
    "# Apache Arrow with Pandas and Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.csv as pc\n",
    "import pyarrow.parquet as pq\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amber-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_name = 'Building_Permits.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-privacy",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latter-prayer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zkan/Labs/hello-arrow/ENV/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (22,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "pandas_df = pd.read_csv(csv_file_name)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mineral-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Pandas read (CSV) in 1.4607 seconds\n"
     ]
    }
   ],
   "source": [
    "print(type(pandas_df))\n",
    "print(f'Pandas read (CSV) in {toc - tic:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-cycle",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[1]').appName('MyApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recognized-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "spark_df = spark.read.csv(csv_file_name)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "numerous-conducting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "PySpark read (CSV) in 3.7077 seconds\n"
     ]
    }
   ],
   "source": [
    "print(type(spark_df))\n",
    "print(f'PySpark read (CSV) in {toc - tic:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-rachel",
   "metadata": {},
   "source": [
    "## Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uniform-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "table = pc.read_csv(csv_file_name)\n",
    "df = table.to_pandas()\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virgin-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Arrow read (CSV to Pandas) in 0.5448 seconds\n"
     ]
    }
   ],
   "source": [
    "print(type(df))\n",
    "print(f'Arrow read (CSV to Pandas) in {toc - tic:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "standing-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "spark_df.toPandas()\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "olive-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "Spark DF to Pandas without Arrow in 8.2552 seconds\n"
     ]
    }
   ],
   "source": [
    "print(type(spark_df))\n",
    "print(f'Spark DF to Pandas without Arrow in {toc - tic:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-welsh",
   "metadata": {},
   "source": [
    "Got memory leak issue. Set OS environment variable `export ARROW_PRE_0_15_IPC_FORMAT=1`. (Credit: https://george-jen.gitbook.io/data-science-and-apache-spark/enabling-for-conversion-to-from-pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charged-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rapid-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zkan/Labs/hello-arrow/ENV/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:88: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  Arrow legacy IPC format is not supported in PySpark, please unset ARROW_PRE_0_15_IPC_FORMAT\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "spark_df.toPandas()\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "imperial-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "Spark DF to Pandas using Arrow in 6.4608 seconds\n"
     ]
    }
   ],
   "source": [
    "print(type(spark_df))\n",
    "print(f'Spark DF to Pandas using Arrow in {toc - tic:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-mauritius",
   "metadata": {},
   "source": [
    "### With Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dying-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquert_file_name = 'building_permits.parquet'\n",
    "pq.write_table(table, parquert_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "developmental-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "pdf = pd.read_parquet(parquert_file_name)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fitted-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas read (Parquet) in 0.5176 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Pandas read (Parquet) in {toc - tic:0.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "martial-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "table = pq.read_table(parquert_file_name)\n",
    "toc = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "charitable-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrow read (Parquet) in 0.1697 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'Arrow read (Parquet) in {toc - tic:0.4f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
